{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:39:04.091732Z",
     "start_time": "2021-04-10T02:38:50.096917Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PyPDF2 import PdfFileReader\n",
    "from tika import parser\n",
    "from datetime import datetime\n",
    "\n",
    "import re \n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd().replace('\\\\', '/') + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:39:04.125555Z",
     "start_time": "2021-04-10T02:39:04.101094Z"
    }
   },
   "outputs": [],
   "source": [
    "path_data = cwd + 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "##### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:39:04.308434Z",
     "start_time": "2021-04-10T02:39:04.143510Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Preprocess_PDF(file, print_text=False) : \n",
    "\n",
    "    print(file)\n",
    "    text = parser.from_file(path_data + file)['content']\n",
    "\n",
    "    # get the text content\n",
    "    text = text.split('Legal Information and Disclosures')[0]\n",
    "    text = text.split('Re:')[-1]\n",
    "    text = text.lower() # don't lower case names e.g. Warren Buffett\n",
    "\n",
    "    # remove url\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # replace special characters\n",
    "    text = re.sub('oaktree capital management l.p. all rights reserved', '', text)\n",
    "    text = re.sub(\"(\\n)\\d{1}\\s\", '', text) # e.g. \\n2 for page 2\n",
    "\n",
    "    to_replace = ['\\n', ':', '*', \"'\", \"’\", '“', '”', '.  .  .', '. . .', '. .', '[', ']', \n",
    "                 'l.p. all rights reserved', 'oaktree capital management', '\\uf0b7',\n",
    "                 'follow us', 'l.p.', 'all rights reserved',\n",
    "                 ]\n",
    "    for char in to_replace : text = text.replace(char, '') \n",
    "    text = text.replace('-', ' ').replace('—', ' ').replace('–', ' ')\n",
    "    text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\;\\\"]\", \" \", text)\n",
    "    text = re.sub(\"(©)+\\s\\d{4}\\s\",'', text) # e.g. @2017\n",
    "    text = text.replace('©', ' ')\n",
    "    \n",
    "    # remove white space\n",
    "    text = \" \".join(text.strip().split())\n",
    "\n",
    "    # Memo date\n",
    "    written_date = re.findall(\"(\\w+\\s\\d+\\s\\d{4})\", text)[-1]\n",
    "    if file[:10].replace('-', '').isnumeric() : date = file[:10] # '-'.join(file.split('-')[:3])\n",
    "    else : date = datetime.strptime(written_date, \"%B %d %Y\").strftime(\"%Y-%m-%d\")\n",
    "    text = text.replace(written_date, '')\n",
    "    text = text.strip()\n",
    "    \n",
    "    full_text = text\n",
    "    \n",
    "    # remove special characters\n",
    "    # text = re.sub(r'\\W+', ' ', text)\n",
    "    text = re.sub('[^.a-zA-Z0-9 \\n\\.]', '', text) # keep dots\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # remove stop words\n",
    "    text = ' '.join([w for w in text.split() if w not in stopwords])\n",
    "    \n",
    "    # lemmatize\n",
    "    text = ' '.join([WordNetLemmatizer().lemmatize(w) for w in text.split()])\n",
    "\n",
    "    # remove 1 and 2-letter words\n",
    "    text = re.sub(r'\\b\\w{1}\\b', ' ', text)\n",
    "    text = re.sub(r'\\b\\w{2}\\b', ' ', text)\n",
    "    \n",
    "    # replace multiple dots\n",
    "    text = re.sub(\"[.]{2,}\", '.', text)\n",
    "    text = re.sub(\"[.]\\s[.]\", '.', text)\n",
    "    \n",
    "    # remove white space\n",
    "    text = \" \".join(text.strip().split())\n",
    "    \n",
    "    if print_text : print(text)\n",
    "        \n",
    "    return text, full_text, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:40:06.903625Z",
     "start_time": "2021-04-10T02:39:57.480688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-10-12-the-route-to-performance.pdf\n",
      "route performance seek investment performance average achieve remains major question. view subject come increasingly focus year gone two event late september especially juxtaposition made even clearer best pursue superior results. first article wall street journal prominent money management firm lagging performance. equity result basis point behind twelve month august result five year performance fallen behind well. president firm explained bold weighting werent wrong early. explanation strongly disagree want top money manager willing bottom too. call mind convertible mutual fund discussed second quarter letter convertible clients. fund held large amount common stock first eight month cash that. result return basis point better average convertible fund year . ahead second place fund. next half year tactic equally divergent . wrong time producing performance far enough behind negate majority achievement pull month result well back pack. observation time mirrored fund manager quoted negative viewpoint order strive performance far different norm better must thing expose possibility far different norm worse. case illustrate bold step taken pursuit great performance easily wrong right. even worse combination far average far average year lead long term record characterized volatility uandu mediocrity. alternative would like cite approach major mid west pension plan whose director spoke last month. return plan equity last fourteen year direction man predecessor way ahead . shared considered key never year percentile period percentile. result fourth percentile fourteen year period whole. feel strongly attempting achieve superior long term record stringing together run top decile year unlikely succeed. rather striving little better average every year discipline highly superior relative result bad time likely produce extreme volatility likely produce huge loss cant recouped importantly likely work given fact human . simply put pension fund record tell equity avoid loser losing year winner take care themselves. believe strongly hold true group opportunistic niche well best foundation average long term performance absence disasters. reason quest consistency protection single year greatness common thread underlying investment product uin convertiblesu insist call potential appreciation accompanied average resistance declines. uin high yield bondsu strive raise relative performance avoiding credit loss reaching higher uncertain yields. uin distressed company debtu buy believe cost price fully covered asset values. always case year right take risk better . long run however feel strongly seeking relative performance little bit average consistent basis protection poor absolute result tough time prove effective swinging fences.\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(path_data)\n",
    "file = files[0]\n",
    "text, full_text, date = Preprocess_PDF(file, print_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:41:27.008843Z",
     "start_time": "2021-04-10T02:40:17.848081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1990 to 2020, Howard Mark wrote 132 memos, totalling 1459 pages\n"
     ]
    }
   ],
   "source": [
    "# Count number of pages in total\n",
    "\n",
    "num_pages = 0\n",
    "num_memo = 0 # 132 in total\n",
    "for file in files : \n",
    "    pdf = PdfFileReader(open(path_data + file, 'rb'))\n",
    "    try : \n",
    "        num_pages += int(parser.from_file(path_data + file)['metadata']['xmpTPg:NPages'])\n",
    "        num_memo +=1\n",
    "    except : pass\n",
    "    \n",
    "print('From 1990 to 2020, Howard Mark wrote %i memos, totalling %i pages' % (num_memo, num_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T02:41:27.464352Z",
     "start_time": "2021-04-10T02:41:27.015447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_memo</th>\n",
       "      <th>full_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-10-12</th>\n",
       "      <td>route performance seek investment performance ...</td>\n",
       "      <td>the route to performance we all seek investmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-11</th>\n",
       "      <td>first quarter performance mood swing security ...</td>\n",
       "      <td>first quarter performance the mood swings of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-10-08</th>\n",
       "      <td>microeconomics supply demand convertible two p...</td>\n",
       "      <td>microeconomics 101 supply demand and convertib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-15</th>\n",
       "      <td>value prediction whered rain come anyone clien...</td>\n",
       "      <td>the value of predictions or whered all this ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-24</th>\n",
       "      <td>addendum third quarter client letter howard ur...</td>\n",
       "      <td>addendum to third quarter client letter from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>latest update going provide information view t...</td>\n",
       "      <td>latest update im going to do all i can to prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19</th>\n",
       "      <td>market know buddy sandy airline pilot. asked d...</td>\n",
       "      <td>what does the market know my buddy sandy was a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>way last six week market seen best time worst ...</td>\n",
       "      <td>which way now in the last six weeks the market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-07</th>\n",
       "      <td>yet july generated response year ive writing m...</td>\n",
       "      <td>yet again there they go again again of july 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>bet ive written past memo indelible recollecti...</td>\n",
       "      <td>you bet as ive written in past memos i have an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            preprocessed_memo  \\\n",
       "1990-10-12  route performance seek investment performance ...   \n",
       "1991-04-11  first quarter performance mood swing security ...   \n",
       "1992-10-08  microeconomics supply demand convertible two p...   \n",
       "1993-02-15  value prediction whered rain come anyone clien...   \n",
       "1994-01-24  addendum third quarter client letter howard ur...   \n",
       "...                                                       ...   \n",
       "2020-03-19  latest update going provide information view t...   \n",
       "2016-01-19  market know buddy sandy airline pilot. asked d...   \n",
       "2020-03-31  way last six week market seen best time worst ...   \n",
       "2017-09-07  yet july generated response year ive writing m...   \n",
       "2020-01-13  bet ive written past memo indelible recollecti...   \n",
       "\n",
       "                                               full_sentences  \n",
       "1990-10-12  the route to performance we all seek investmen...  \n",
       "1991-04-11  first quarter performance the mood swings of t...  \n",
       "1992-10-08  microeconomics 101 supply demand and convertib...  \n",
       "1993-02-15  the value of predictions or whered all this ra...  \n",
       "1994-01-24  addendum to third quarter client letter from h...  \n",
       "...                                                       ...  \n",
       "2020-03-19  latest update im going to do all i can to prov...  \n",
       "2016-01-19  what does the market know my buddy sandy was a...  \n",
       "2020-03-31  which way now in the last six weeks the market...  \n",
       "2017-09-07  yet again there they go again again of july 26...  \n",
       "2020-01-13  you bet as ive written in past memos i have an...  \n",
       "\n",
       "[132 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save results\n",
    "preprocess_memos=False # take 35s\n",
    "if preprocess_memos :\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for file in files : \n",
    "\n",
    "        text1 = parser.from_file(path_data + file)['content']\n",
    "        print(len(text1))\n",
    "\n",
    "        text, full_text, date = Preprocess_PDF(file, print_text=False)\n",
    "        df.loc[date, 'preprocessed_memo'] = text\n",
    "        df.loc[date, 'full_sentences'] = full_text\n",
    "\n",
    "        print(len(text), '\\n')\n",
    "\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    save=False\n",
    "    if save : \n",
    "        df.to_csv(cwd + 'Output/' + 'Preprocessed_Memos.csv')\n",
    "\n",
    "else : \n",
    "    df = pd.read_csv(cwd + 'Output/' + 'Preprocessed_Memos.csv', index_col=0)\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
